# DataSage
DataSage is a fully local, extensible Retrieval-Augmented Generation (RAG) engine designed for flexible data ingestion, semantic search, and context-aware question answering. It supports pdf, txt, csv, and xslx; and uses modern open-source LLM tooling such as Ollama - with zero cloud dependencies.

ğŸŒŸ Features

Document Ingestion: Support for multiple file formats (CSV, PDF, TXT)
Intelligent Chunking: Configurable text splitting with overlap for context preservation
Vector Storage: ChromaDB-backed vector database for efficient similarity search
Semantic Search: HuggingFace embeddings for accurate document retrieval
LLM Integration: Local LLM support via Ollama for answer generation
Modular Architecture: Easy to extend and customize components

ğŸ—ï¸ Architecture
DataSage
â”œâ”€â”€ Ingestion Layer     â†’ Load and chunk documents
â”œâ”€â”€ Indexing Layer      â†’ Embed and store in vector database
â”œâ”€â”€ Query Layer         â†’ Retrieve relevant context and generate answers
â””â”€â”€ RAG Pipeline        â†’ End-to-end question answering system
ğŸ“‹ Prerequisites

Python 3.8+
Ollama (for local LLM inference)

ğŸš€ Installation
1. Clone the repository
bashgit clone https://github.com/yourusername/datasage.git
cd datasage
2. Install dependencies
bashpip install -r requirements.txt
Required packages:
txtlangchain
langchain-huggingface
langchain-chroma
langchain-ollama
langchain-core
chromadb
sentence-transformers
pypdf
3. Install Ollama
Download and install Ollama from ollama.com
Pull a model:
bashollama pull llama3.1
Verify installation:
bashollama run llama3.1

ğŸ“ Project Structure
datasage/
â”œâ”€â”€ indexing/
â”‚   â”œâ”€â”€ embedder.py          # Text embedding using HuggingFace
â”‚   â”œâ”€â”€ vector_store.py      # ChromaDB vector storage
â”‚   â””â”€â”€ index_engine.py      # High-level indexing pipeline
â”œâ”€â”€ ingestion/
â”‚   â”œâ”€â”€ loaders.py           # Document loaders (PDF, CSV, TXT)
â”‚   â””â”€â”€ chunker.py           # Text chunking utilities
â”œâ”€â”€ query/
â”‚   â”œâ”€â”€ retriever.py         # Semantic search retriever
â”‚   â””â”€â”€ generator.py         # LLM answer generation
â””â”€â”€ __init__.py
Supported File Formats

CSV: Loaded with metadata for each row
PDF: Extracted page by page
TXT: Loaded as single document

ğŸ¯ Use Cases

Document Q&A: Query large documents using natural language
Knowledge Base Search: Build searchable knowledge bases
Customer Support: Answer questions from documentation
Research Assistant: Extract information from academic papers
Code Documentation: Query codebases and technical docs

ğŸ“ License
This project is licensed under the MIT License - see the LICENSE file for details.
ğŸ™ Acknowledgments

Built with LangChain
Embeddings powered by HuggingFace
Vector storage by ChromaDB
Local LLM inference via Ollama

ğŸ“§ Contact
For questions or support, please open an issue on GitHub.

Made with â¤ï¸ by the DataSage Team
